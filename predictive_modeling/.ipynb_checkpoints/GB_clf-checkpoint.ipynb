{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/acc_df.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ac = Acc_data('../data/cleaned/coll_coord.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Ac.get_all_coll() #['']\n",
    "acc['ds']=acc.INCDTTM.apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "us_holidays=holidays.UnitedStates()\n",
    "acc['holiday']=acc.ds.apply(lambda x: (x in us_holidays)*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_04_18 = acc[(acc['year'] != 2019) & (acc['year'] != 2003 )]\n",
    "acc_w = acc_04_18[['year','week','OBJECTID']].groupby(['year','week']).count()\n",
    "acc_wh = acc_04_18[['year','week','holiday']].groupby(['year','week']).max()\n",
    "acc_w = acc_w.join(acc_wh)\n",
    "len(acc_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average for each week in year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>acc_nr</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  week  acc_nr  holiday\n",
       "0  2004     1     142        1\n",
       "1  2004     2     263        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_numbers = acc_w.reset_index()\n",
    "week_numbers.rename({'OBJECTID': 'acc_nr'}, axis=1, inplace=True)\n",
    "week_numbers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_nr    228.2\n",
       "Name: 4, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_means.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>acc_nr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>week_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>240.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>260.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>234.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>228.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>251.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>236.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>231.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>221.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>242.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>245.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "      <td>244.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>235.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>252.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>249.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2004</td>\n",
       "      <td>15</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>249.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2004</td>\n",
       "      <td>16</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>239.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2004</td>\n",
       "      <td>17</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>248.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2004</td>\n",
       "      <td>18</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>258.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2004</td>\n",
       "      <td>19</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>255.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2004</td>\n",
       "      <td>20</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>264.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2004</td>\n",
       "      <td>21</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>250.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2004</td>\n",
       "      <td>22</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>258.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2004</td>\n",
       "      <td>23</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>268.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>258.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2004</td>\n",
       "      <td>25</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>252.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2004</td>\n",
       "      <td>26</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>256.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2004</td>\n",
       "      <td>27</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>246.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2004</td>\n",
       "      <td>28</td>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>256.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2004</td>\n",
       "      <td>29</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2004</td>\n",
       "      <td>30</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>260.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2018</td>\n",
       "      <td>23</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>268.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2018</td>\n",
       "      <td>24</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>258.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2018</td>\n",
       "      <td>25</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>252.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2018</td>\n",
       "      <td>26</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>256.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2018</td>\n",
       "      <td>27</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>246.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "      <td>256.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2018</td>\n",
       "      <td>30</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>260.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2018</td>\n",
       "      <td>31</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>265.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>2018</td>\n",
       "      <td>32</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>250.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>2018</td>\n",
       "      <td>33</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>254.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>2018</td>\n",
       "      <td>34</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>252.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2018</td>\n",
       "      <td>35</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>249.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>2018</td>\n",
       "      <td>36</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>240.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>2018</td>\n",
       "      <td>37</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>262.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>2018</td>\n",
       "      <td>38</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>257.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>2018</td>\n",
       "      <td>39</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>267.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>2018</td>\n",
       "      <td>40</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>273.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>2018</td>\n",
       "      <td>41</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>266.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>271.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2018</td>\n",
       "      <td>43</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>282.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2018</td>\n",
       "      <td>44</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>296.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2018</td>\n",
       "      <td>45</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2018</td>\n",
       "      <td>46</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>268.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>2018</td>\n",
       "      <td>47</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>248.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>2018</td>\n",
       "      <td>48</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>252.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>2018</td>\n",
       "      <td>49</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>256.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>2018</td>\n",
       "      <td>50</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>276.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>2018</td>\n",
       "      <td>51</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>268.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>2018</td>\n",
       "      <td>52</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>196.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>786 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  week  acc_nr  holiday   week_mean\n",
       "0    2004     1     142        1  240.533333\n",
       "1    2004     2     263        0  260.800000\n",
       "2    2004     3     291        0  234.133333\n",
       "3    2004     4     222        1  228.200000\n",
       "4    2004     5     277        0  251.133333\n",
       "5    2004     6     249        0  236.933333\n",
       "6    2004     7     251        0  231.933333\n",
       "7    2004     8     236        1  221.266667\n",
       "8    2004     9     265        0  242.600000\n",
       "9    2004    10     257        0  245.133333\n",
       "10   2004    11     259        0  244.333333\n",
       "11   2004    12     266        0  235.866667\n",
       "12   2004    13     302        0  252.133333\n",
       "13   2004    14     279        0  249.266667\n",
       "14   2004    15     263        0  249.333333\n",
       "15   2004    16     279        0  239.733333\n",
       "16   2004    17     293        0  248.200000\n",
       "17   2004    18     281        0  258.200000\n",
       "18   2004    19     305        0  255.333333\n",
       "19   2004    20     275        0  264.866667\n",
       "20   2004    21     280        0  250.933333\n",
       "21   2004    22     337        0  258.866667\n",
       "22   2004    23     279        1  268.600000\n",
       "23   2004    24     311        0  258.333333\n",
       "24   2004    25     266        0  252.333333\n",
       "25   2004    26     276        0  256.666667\n",
       "26   2004    27     268        1  246.733333\n",
       "27   2004    28     293        1  256.200000\n",
       "28   2004    29     276        0  257.000000\n",
       "29   2004    30     297        0  260.400000\n",
       "..    ...   ...     ...      ...         ...\n",
       "756  2018    23     278        0  268.600000\n",
       "757  2018    24     207        0  258.333333\n",
       "758  2018    25     213        0  252.333333\n",
       "759  2018    26     217        0  256.666667\n",
       "760  2018    27     190        1  246.733333\n",
       "761  2018    28     259        0  256.200000\n",
       "762  2018    29     285        0  257.000000\n",
       "763  2018    30     223        0  260.400000\n",
       "764  2018    31     210        0  265.466667\n",
       "765  2018    32     248        0  250.333333\n",
       "766  2018    33     216        0  254.466667\n",
       "767  2018    34     179        0  252.600000\n",
       "768  2018    35     211        0  249.800000\n",
       "769  2018    36     196        1  240.266667\n",
       "770  2018    37     222        0  262.200000\n",
       "771  2018    38     246        0  257.866667\n",
       "772  2018    39     230        0  267.200000\n",
       "773  2018    40     233        0  273.266667\n",
       "774  2018    41     215        1  266.200000\n",
       "775  2018    42     226        0  271.466667\n",
       "776  2018    43     289        0  282.733333\n",
       "777  2018    44     255        0  296.933333\n",
       "778  2018    45     220        1  272.000000\n",
       "779  2018    46     260        1  268.733333\n",
       "780  2018    47     159        1  248.866667\n",
       "781  2018    48     261        0  252.466667\n",
       "782  2018    49     274        0  256.400000\n",
       "783  2018    50     275        0  276.600000\n",
       "784  2018    51     234        0  268.133333\n",
       "785  2018    52     150        1  196.066667\n",
       "\n",
       "[786 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_means=week_numbers[['week','acc_nr']].groupby(['week']).mean()\n",
    "week_numbers['week_mean']=week_numbers.week.apply(lambda x: week_means['acc_nr'][x])\n",
    "week_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.49236641221373"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average over year\n",
    "week_numbers.acc_nr.sum()/len(week_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other data / dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>acc_nr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>week_mean</th>\n",
       "      <th>year_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>252.466667</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>256.400000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>276.600000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>268.133333</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>196.066667</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5  6  7  8  9  10  ...  48  49  50  51  52  53  acc_nr  \\\n",
       "781  0  0  0  0  0  0  0  0  0   0  ...   1   0   0   0   0   0     261   \n",
       "782  0  0  0  0  0  0  0  0  0   0  ...   0   1   0   0   0   0     274   \n",
       "783  0  0  0  0  0  0  0  0  0   0  ...   0   0   1   0   0   0     275   \n",
       "784  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   1   0   0     234   \n",
       "785  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   1   0     150   \n",
       "\n",
       "     holiday   week_mean  year_red  \n",
       "781        0  252.466667        14  \n",
       "782        0  256.400000        14  \n",
       "783        0  276.600000        14  \n",
       "784        0  268.133333        14  \n",
       "785        1  196.066667        14  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_d = pd.get_dummies(week_numbers.week).join(week_numbers)\n",
    "week_d['year_red']= week_d.year.apply(lambda x: x-2004)\n",
    "week_d.drop(['week','year'], axis=1, inplace=True)\n",
    "# week_d['week_avg']=252.49\n",
    "week_d.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=acc_ds[['year','month','week','day','weekday']]\n",
    "X = week_d.drop(['acc_nr'], axis=1)\n",
    "y=week_d['acc_nr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(learning_rate=0.001, \n",
    "                                  n_estimators=5000, #boosting stages to perform\n",
    "                                  max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69624161e-02, 8.11928284e-03, 5.50223742e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.54224531e-04, 0.00000000e+00, 1.69717612e-03,\n",
       "       1.57649354e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.67514486e-04, 4.20457059e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.21266096e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.22768664e-03, 5.15860731e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.52790049e-04, 0.00000000e+00, 1.06314930e-04,\n",
       "       6.83969724e-05, 0.00000000e+00, 3.19005523e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.50627798e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.88611890e-04, 2.95916274e-04, 0.00000000e+00,\n",
       "       4.83224600e-04, 0.00000000e+00, 8.69846741e-04, 4.29706742e-03,\n",
       "       3.09968954e-05, 1.04037086e-03, 9.47069079e-03, 1.27250524e-03,\n",
       "       1.21433097e-03, 0.00000000e+00, 4.38731145e-03, 1.91316601e-05,\n",
       "       1.28323845e-02, 1.62353737e-02, 3.14470385e-01, 5.98951457e-01])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6386324389470801"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5806200790025627"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(learning_rate= 0.001, #0.001, \n",
    "                                  n_estimators= 5000, #5000, #boosting stages to perform\n",
    "                                  max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6623250781121466"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575698706773569"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 40 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   13.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_sampl...=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.001, 0.0001], 'max_depth': [3, 4, 5, 6], 'n_estimators': [50, 100, 500, 1000, 5000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    grid = {\n",
    "        'learning_rate': [0.001,0.0001],\n",
    "        'max_depth': [3,4,5,6],\n",
    "#         'min_samples_leaf': [1,2,3,4,5],\n",
    "#         'max_features': ['sqrt',None],\n",
    "        'n_estimators': [50,100,500,1000,5000],\n",
    "#         'random_state': [0]\n",
    "    }\n",
    "else:  # TEST\n",
    "    grid = {\n",
    "    'learning_rate': [1],\n",
    "    'max_depth': [2], \n",
    "    'min_samples_leaf': [2],\n",
    "#     'max_features': ['sqrt', None],\n",
    "    'n_estimators': [2],\n",
    "    'random_state': [0]\n",
    "}\n",
    "    \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# confusion_score = make_scorer(confusion_rmse, greater_is_better=False)\n",
    "gbc_grid_cv = GridSearchCV(\n",
    "    GradientBoostingRegressor(), \n",
    "    grid,\n",
    "    cv=2,  # number of folds\n",
    "    return_train_score=True,\n",
    "    verbose=1, \n",
    "    n_jobs=-1)\n",
    "gbc_grid_cv.fit(X, y)\n",
    "# Collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.001, loss='ls', max_depth=4,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "             n_iter_no_change=None, presort='auto', random_state=None,\n",
       "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002564928002457337"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028286</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>-0.296714</td>\n",
       "      <td>-0.515912</td>\n",
       "      <td>-0.406313</td>\n",
       "      <td>0.109599</td>\n",
       "      <td>29</td>\n",
       "      <td>0.032566</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.041492</td>\n",
       "      <td>0.008927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049232</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>-0.278601</td>\n",
       "      <td>-0.418166</td>\n",
       "      <td>-0.348384</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>22</td>\n",
       "      <td>0.062480</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.017560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.292728</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>-0.235196</td>\n",
       "      <td>0.042849</td>\n",
       "      <td>-0.096173</td>\n",
       "      <td>0.139023</td>\n",
       "      <td>8</td>\n",
       "      <td>0.234001</td>\n",
       "      <td>0.357165</td>\n",
       "      <td>0.295583</td>\n",
       "      <td>0.061582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.661119</td>\n",
       "      <td>0.017734</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>-0.257993</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>-0.011916</td>\n",
       "      <td>0.246077</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352395</td>\n",
       "      <td>0.509369</td>\n",
       "      <td>0.430882</td>\n",
       "      <td>0.078487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.034174</td>\n",
       "      <td>0.031077</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_es...</td>\n",
       "      <td>-0.394186</td>\n",
       "      <td>0.190783</td>\n",
       "      <td>-0.101702</td>\n",
       "      <td>0.292484</td>\n",
       "      <td>10</td>\n",
       "      <td>0.568327</td>\n",
       "      <td>0.707113</td>\n",
       "      <td>0.637720</td>\n",
       "      <td>0.069393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.034066</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 4, 'n_es...</td>\n",
       "      <td>-0.302457</td>\n",
       "      <td>-0.507174</td>\n",
       "      <td>-0.404815</td>\n",
       "      <td>0.102359</td>\n",
       "      <td>28</td>\n",
       "      <td>0.038248</td>\n",
       "      <td>0.057765</td>\n",
       "      <td>0.048007</td>\n",
       "      <td>0.009759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.082553</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 4, 'n_es...</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>-0.405618</td>\n",
       "      <td>-0.346601</td>\n",
       "      <td>0.059017</td>\n",
       "      <td>19</td>\n",
       "      <td>0.072922</td>\n",
       "      <td>0.110163</td>\n",
       "      <td>0.091542</td>\n",
       "      <td>0.018620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.466416</td>\n",
       "      <td>0.019147</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 4, 'n_es...</td>\n",
       "      <td>-0.261396</td>\n",
       "      <td>0.104754</td>\n",
       "      <td>-0.078321</td>\n",
       "      <td>0.183075</td>\n",
       "      <td>5</td>\n",
       "      <td>0.281466</td>\n",
       "      <td>0.398309</td>\n",
       "      <td>0.339888</td>\n",
       "      <td>0.058421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.946202</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 4, 'n_es...</td>\n",
       "      <td>-0.266231</td>\n",
       "      <td>0.271360</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.268796</td>\n",
       "      <td>1</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.564233</td>\n",
       "      <td>0.491616</td>\n",
       "      <td>0.072617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.647011</td>\n",
       "      <td>0.113586</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 4, 'n_es...</td>\n",
       "      <td>-0.481588</td>\n",
       "      <td>0.154313</td>\n",
       "      <td>-0.163637</td>\n",
       "      <td>0.317951</td>\n",
       "      <td>14</td>\n",
       "      <td>0.659658</td>\n",
       "      <td>0.776814</td>\n",
       "      <td>0.718236</td>\n",
       "      <td>0.058578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.062344</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'n_es...</td>\n",
       "      <td>-0.306478</td>\n",
       "      <td>-0.491914</td>\n",
       "      <td>-0.399196</td>\n",
       "      <td>0.092718</td>\n",
       "      <td>25</td>\n",
       "      <td>0.047881</td>\n",
       "      <td>0.062616</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.007368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.117795</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'n_es...</td>\n",
       "      <td>-0.299707</td>\n",
       "      <td>-0.378218</td>\n",
       "      <td>-0.338962</td>\n",
       "      <td>0.039255</td>\n",
       "      <td>17</td>\n",
       "      <td>0.091342</td>\n",
       "      <td>0.119509</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.014083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.566679</td>\n",
       "      <td>0.017994</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'n_es...</td>\n",
       "      <td>-0.306429</td>\n",
       "      <td>0.121723</td>\n",
       "      <td>-0.092353</td>\n",
       "      <td>0.214076</td>\n",
       "      <td>6</td>\n",
       "      <td>0.331880</td>\n",
       "      <td>0.426112</td>\n",
       "      <td>0.378996</td>\n",
       "      <td>0.047116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.022018</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'n_es...</td>\n",
       "      <td>-0.345896</td>\n",
       "      <td>0.258311</td>\n",
       "      <td>-0.043792</td>\n",
       "      <td>0.302103</td>\n",
       "      <td>3</td>\n",
       "      <td>0.486912</td>\n",
       "      <td>0.615817</td>\n",
       "      <td>0.551365</td>\n",
       "      <td>0.064453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.449611</td>\n",
       "      <td>0.115501</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 5, 'n_es...</td>\n",
       "      <td>-0.553148</td>\n",
       "      <td>0.089949</td>\n",
       "      <td>-0.231599</td>\n",
       "      <td>0.321549</td>\n",
       "      <td>15</td>\n",
       "      <td>0.742957</td>\n",
       "      <td>0.842246</td>\n",
       "      <td>0.792601</td>\n",
       "      <td>0.049644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.043467</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'n_es...</td>\n",
       "      <td>-0.315425</td>\n",
       "      <td>-0.501372</td>\n",
       "      <td>-0.408399</td>\n",
       "      <td>0.092974</td>\n",
       "      <td>32</td>\n",
       "      <td>0.056848</td>\n",
       "      <td>0.068749</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.005950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.087490</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'n_es...</td>\n",
       "      <td>-0.317610</td>\n",
       "      <td>-0.396682</td>\n",
       "      <td>-0.357146</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>24</td>\n",
       "      <td>0.108329</td>\n",
       "      <td>0.130952</td>\n",
       "      <td>0.119640</td>\n",
       "      <td>0.011311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'n_es...</td>\n",
       "      <td>-0.348096</td>\n",
       "      <td>0.081159</td>\n",
       "      <td>-0.133468</td>\n",
       "      <td>0.214627</td>\n",
       "      <td>13</td>\n",
       "      <td>0.393372</td>\n",
       "      <td>0.464091</td>\n",
       "      <td>0.428731</td>\n",
       "      <td>0.035359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.185467</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'n_es...</td>\n",
       "      <td>-0.412441</td>\n",
       "      <td>0.201229</td>\n",
       "      <td>-0.105606</td>\n",
       "      <td>0.306835</td>\n",
       "      <td>11</td>\n",
       "      <td>0.567123</td>\n",
       "      <td>0.657125</td>\n",
       "      <td>0.612124</td>\n",
       "      <td>0.045001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.119468</td>\n",
       "      <td>0.090195</td>\n",
       "      <td>0.026437</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 6, 'n_es...</td>\n",
       "      <td>-0.644893</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>-0.318732</td>\n",
       "      <td>0.326160</td>\n",
       "      <td>16</td>\n",
       "      <td>0.836340</td>\n",
       "      <td>0.898052</td>\n",
       "      <td>0.867196</td>\n",
       "      <td>0.030856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.019760</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>-0.314588</td>\n",
       "      <td>-0.609697</td>\n",
       "      <td>-0.462142</td>\n",
       "      <td>0.147554</td>\n",
       "      <td>40</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.038345</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>-0.312607</td>\n",
       "      <td>-0.598789</td>\n",
       "      <td>-0.455698</td>\n",
       "      <td>0.143091</td>\n",
       "      <td>35</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.008628</td>\n",
       "      <td>0.001859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.335193</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>-0.296826</td>\n",
       "      <td>-0.515957</td>\n",
       "      <td>-0.406391</td>\n",
       "      <td>0.109565</td>\n",
       "      <td>30</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.050397</td>\n",
       "      <td>0.041475</td>\n",
       "      <td>0.008923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.605536</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>-0.278457</td>\n",
       "      <td>-0.418163</td>\n",
       "      <td>-0.348310</td>\n",
       "      <td>0.069853</td>\n",
       "      <td>21</td>\n",
       "      <td>0.062455</td>\n",
       "      <td>0.097576</td>\n",
       "      <td>0.080015</td>\n",
       "      <td>0.017560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.396726</td>\n",
       "      <td>0.233479</td>\n",
       "      <td>0.014066</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 3, 'n_e...</td>\n",
       "      <td>-0.235124</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>-0.096251</td>\n",
       "      <td>0.138873</td>\n",
       "      <td>9</td>\n",
       "      <td>0.233963</td>\n",
       "      <td>0.357059</td>\n",
       "      <td>0.295511</td>\n",
       "      <td>0.061548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.031576</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>-0.315263</td>\n",
       "      <td>-0.608962</td>\n",
       "      <td>-0.462113</td>\n",
       "      <td>0.146850</td>\n",
       "      <td>38</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.061609</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>-0.313953</td>\n",
       "      <td>-0.597295</td>\n",
       "      <td>-0.455624</td>\n",
       "      <td>0.141671</td>\n",
       "      <td>34</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>0.012011</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.002029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.440291</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>-0.302321</td>\n",
       "      <td>-0.507250</td>\n",
       "      <td>-0.404785</td>\n",
       "      <td>0.102464</td>\n",
       "      <td>27</td>\n",
       "      <td>0.038232</td>\n",
       "      <td>0.057741</td>\n",
       "      <td>0.047986</td>\n",
       "      <td>0.009754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.818917</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>-0.287709</td>\n",
       "      <td>-0.405720</td>\n",
       "      <td>-0.346714</td>\n",
       "      <td>0.059006</td>\n",
       "      <td>20</td>\n",
       "      <td>0.072893</td>\n",
       "      <td>0.110118</td>\n",
       "      <td>0.091506</td>\n",
       "      <td>0.018613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.007068</td>\n",
       "      <td>0.126011</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>-0.261249</td>\n",
       "      <td>0.104676</td>\n",
       "      <td>-0.078287</td>\n",
       "      <td>0.182963</td>\n",
       "      <td>4</td>\n",
       "      <td>0.281419</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.339824</td>\n",
       "      <td>0.058406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.037612</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>-0.315527</td>\n",
       "      <td>-0.607105</td>\n",
       "      <td>-0.461316</td>\n",
       "      <td>0.145789</td>\n",
       "      <td>37</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.072295</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>-0.314443</td>\n",
       "      <td>-0.593649</td>\n",
       "      <td>-0.454046</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>33</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.548283</td>\n",
       "      <td>0.013192</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>-0.306666</td>\n",
       "      <td>-0.491969</td>\n",
       "      <td>-0.399318</td>\n",
       "      <td>0.092651</td>\n",
       "      <td>26</td>\n",
       "      <td>0.047860</td>\n",
       "      <td>0.062589</td>\n",
       "      <td>0.055225</td>\n",
       "      <td>0.007365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.977328</td>\n",
       "      <td>0.011119</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>-0.299771</td>\n",
       "      <td>-0.378336</td>\n",
       "      <td>-0.339053</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>18</td>\n",
       "      <td>0.091302</td>\n",
       "      <td>0.119450</td>\n",
       "      <td>0.105376</td>\n",
       "      <td>0.014074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.658381</td>\n",
       "      <td>0.117459</td>\n",
       "      <td>0.022428</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 5, 'n_e...</td>\n",
       "      <td>-0.306256</td>\n",
       "      <td>0.121537</td>\n",
       "      <td>-0.092359</td>\n",
       "      <td>0.213896</td>\n",
       "      <td>7</td>\n",
       "      <td>0.331793</td>\n",
       "      <td>0.426001</td>\n",
       "      <td>0.378897</td>\n",
       "      <td>0.047104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.044635</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 6, 'n_e...</td>\n",
       "      <td>-0.316191</td>\n",
       "      <td>-0.608092</td>\n",
       "      <td>-0.462141</td>\n",
       "      <td>0.145951</td>\n",
       "      <td>39</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.087114</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 6, 'n_e...</td>\n",
       "      <td>-0.315803</td>\n",
       "      <td>-0.595614</td>\n",
       "      <td>-0.455709</td>\n",
       "      <td>0.139905</td>\n",
       "      <td>36</td>\n",
       "      <td>0.011823</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.013061</td>\n",
       "      <td>0.001238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.657863</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 6, 'n_e...</td>\n",
       "      <td>-0.315289</td>\n",
       "      <td>-0.501415</td>\n",
       "      <td>-0.408352</td>\n",
       "      <td>0.093063</td>\n",
       "      <td>31</td>\n",
       "      <td>0.056824</td>\n",
       "      <td>0.068719</td>\n",
       "      <td>0.062771</td>\n",
       "      <td>0.005948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.162543</td>\n",
       "      <td>0.066556</td>\n",
       "      <td>0.007922</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 6, 'n_e...</td>\n",
       "      <td>-0.317516</td>\n",
       "      <td>-0.396766</td>\n",
       "      <td>-0.357141</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>23</td>\n",
       "      <td>0.108285</td>\n",
       "      <td>0.130898</td>\n",
       "      <td>0.119592</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.400183</td>\n",
       "      <td>0.093896</td>\n",
       "      <td>0.026643</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'max_depth': 6, 'n_e...</td>\n",
       "      <td>-0.347803</td>\n",
       "      <td>0.081039</td>\n",
       "      <td>-0.133382</td>\n",
       "      <td>0.214421</td>\n",
       "      <td>12</td>\n",
       "      <td>0.393246</td>\n",
       "      <td>0.463977</td>\n",
       "      <td>0.428611</td>\n",
       "      <td>0.035365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.028286      0.001699         0.001620        0.000415   \n",
       "1        0.049232      0.004156         0.001449        0.000147   \n",
       "2        0.292728      0.000634         0.003826        0.000006   \n",
       "3        0.661119      0.017734         0.006322        0.000163   \n",
       "4        3.034174      0.031077         0.021783        0.002335   \n",
       "5        0.034066      0.003270         0.001786        0.000059   \n",
       "6        0.082553      0.000382         0.002272        0.000044   \n",
       "7        0.466416      0.019147         0.004187        0.000229   \n",
       "8        0.946202      0.026689         0.007868        0.000561   \n",
       "9        3.647011      0.113586         0.019526        0.000588   \n",
       "10       0.062344      0.003590         0.001979        0.000069   \n",
       "11       0.117795      0.003272         0.002357        0.000023   \n",
       "12       0.566679      0.017994         0.005028        0.000014   \n",
       "13       1.022018      0.001052         0.007361        0.001296   \n",
       "14       3.449611      0.115501         0.023345        0.001427   \n",
       "15       0.043467      0.000573         0.001379        0.000077   \n",
       "16       0.087490      0.001968         0.001555        0.000024   \n",
       "17       0.681553      0.007952         0.005714        0.000162   \n",
       "18       1.185467      0.048680         0.008736        0.000370   \n",
       "19       4.119468      0.090195         0.026437        0.002341   \n",
       "20       0.019760      0.000973         0.001114        0.000018   \n",
       "21       0.038345      0.002467         0.001208        0.000028   \n",
       "22       0.335193      0.015157         0.004527        0.000612   \n",
       "23       0.605536      0.015982         0.005780        0.000215   \n",
       "24       2.396726      0.233479         0.014066        0.000058   \n",
       "25       0.031576      0.000743         0.001284        0.000027   \n",
       "26       0.061609      0.000489         0.001450        0.000012   \n",
       "27       0.440291      0.009515         0.004482        0.000100   \n",
       "28       0.818917      0.012214         0.006773        0.000562   \n",
       "29       3.007068      0.126011         0.018464        0.000130   \n",
       "30       0.037612      0.000194         0.001307        0.000015   \n",
       "31       0.072295      0.000785         0.001521        0.000003   \n",
       "32       0.548283      0.013192         0.004973        0.000181   \n",
       "33       0.977328      0.011119         0.006840        0.000309   \n",
       "34       3.658381      0.117459         0.022428        0.000916   \n",
       "35       0.044635      0.000902         0.001313        0.000026   \n",
       "36       0.087114      0.000854         0.001560        0.000026   \n",
       "37       0.657863      0.000734         0.005124        0.000482   \n",
       "38       1.162543      0.066556         0.007922        0.000692   \n",
       "39       4.400183      0.093896         0.026643        0.002932   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                0.001               3                 50   \n",
       "1                0.001               3                100   \n",
       "2                0.001               3                500   \n",
       "3                0.001               3               1000   \n",
       "4                0.001               3               5000   \n",
       "5                0.001               4                 50   \n",
       "6                0.001               4                100   \n",
       "7                0.001               4                500   \n",
       "8                0.001               4               1000   \n",
       "9                0.001               4               5000   \n",
       "10               0.001               5                 50   \n",
       "11               0.001               5                100   \n",
       "12               0.001               5                500   \n",
       "13               0.001               5               1000   \n",
       "14               0.001               5               5000   \n",
       "15               0.001               6                 50   \n",
       "16               0.001               6                100   \n",
       "17               0.001               6                500   \n",
       "18               0.001               6               1000   \n",
       "19               0.001               6               5000   \n",
       "20              0.0001               3                 50   \n",
       "21              0.0001               3                100   \n",
       "22              0.0001               3                500   \n",
       "23              0.0001               3               1000   \n",
       "24              0.0001               3               5000   \n",
       "25              0.0001               4                 50   \n",
       "26              0.0001               4                100   \n",
       "27              0.0001               4                500   \n",
       "28              0.0001               4               1000   \n",
       "29              0.0001               4               5000   \n",
       "30              0.0001               5                 50   \n",
       "31              0.0001               5                100   \n",
       "32              0.0001               5                500   \n",
       "33              0.0001               5               1000   \n",
       "34              0.0001               5               5000   \n",
       "35              0.0001               6                 50   \n",
       "36              0.0001               6                100   \n",
       "37              0.0001               6                500   \n",
       "38              0.0001               6               1000   \n",
       "39              0.0001               6               5000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.001, 'max_depth': 3, 'n_es...          -0.296714   \n",
       "1   {'learning_rate': 0.001, 'max_depth': 3, 'n_es...          -0.278601   \n",
       "2   {'learning_rate': 0.001, 'max_depth': 3, 'n_es...          -0.235196   \n",
       "3   {'learning_rate': 0.001, 'max_depth': 3, 'n_es...          -0.257993   \n",
       "4   {'learning_rate': 0.001, 'max_depth': 3, 'n_es...          -0.394186   \n",
       "5   {'learning_rate': 0.001, 'max_depth': 4, 'n_es...          -0.302457   \n",
       "6   {'learning_rate': 0.001, 'max_depth': 4, 'n_es...          -0.287584   \n",
       "7   {'learning_rate': 0.001, 'max_depth': 4, 'n_es...          -0.261396   \n",
       "8   {'learning_rate': 0.001, 'max_depth': 4, 'n_es...          -0.266231   \n",
       "9   {'learning_rate': 0.001, 'max_depth': 4, 'n_es...          -0.481588   \n",
       "10  {'learning_rate': 0.001, 'max_depth': 5, 'n_es...          -0.306478   \n",
       "11  {'learning_rate': 0.001, 'max_depth': 5, 'n_es...          -0.299707   \n",
       "12  {'learning_rate': 0.001, 'max_depth': 5, 'n_es...          -0.306429   \n",
       "13  {'learning_rate': 0.001, 'max_depth': 5, 'n_es...          -0.345896   \n",
       "14  {'learning_rate': 0.001, 'max_depth': 5, 'n_es...          -0.553148   \n",
       "15  {'learning_rate': 0.001, 'max_depth': 6, 'n_es...          -0.315425   \n",
       "16  {'learning_rate': 0.001, 'max_depth': 6, 'n_es...          -0.317610   \n",
       "17  {'learning_rate': 0.001, 'max_depth': 6, 'n_es...          -0.348096   \n",
       "18  {'learning_rate': 0.001, 'max_depth': 6, 'n_es...          -0.412441   \n",
       "19  {'learning_rate': 0.001, 'max_depth': 6, 'n_es...          -0.644893   \n",
       "20  {'learning_rate': 0.0001, 'max_depth': 3, 'n_e...          -0.314588   \n",
       "21  {'learning_rate': 0.0001, 'max_depth': 3, 'n_e...          -0.312607   \n",
       "22  {'learning_rate': 0.0001, 'max_depth': 3, 'n_e...          -0.296826   \n",
       "23  {'learning_rate': 0.0001, 'max_depth': 3, 'n_e...          -0.278457   \n",
       "24  {'learning_rate': 0.0001, 'max_depth': 3, 'n_e...          -0.235124   \n",
       "25  {'learning_rate': 0.0001, 'max_depth': 4, 'n_e...          -0.315263   \n",
       "26  {'learning_rate': 0.0001, 'max_depth': 4, 'n_e...          -0.313953   \n",
       "27  {'learning_rate': 0.0001, 'max_depth': 4, 'n_e...          -0.302321   \n",
       "28  {'learning_rate': 0.0001, 'max_depth': 4, 'n_e...          -0.287709   \n",
       "29  {'learning_rate': 0.0001, 'max_depth': 4, 'n_e...          -0.261249   \n",
       "30  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...          -0.315527   \n",
       "31  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...          -0.314443   \n",
       "32  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...          -0.306666   \n",
       "33  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...          -0.299771   \n",
       "34  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...          -0.306256   \n",
       "35  {'learning_rate': 0.0001, 'max_depth': 6, 'n_e...          -0.316191   \n",
       "36  {'learning_rate': 0.0001, 'max_depth': 6, 'n_e...          -0.315803   \n",
       "37  {'learning_rate': 0.0001, 'max_depth': 6, 'n_e...          -0.315289   \n",
       "38  {'learning_rate': 0.0001, 'max_depth': 6, 'n_e...          -0.317516   \n",
       "39  {'learning_rate': 0.0001, 'max_depth': 6, 'n_e...          -0.347803   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           -0.515912        -0.406313        0.109599               29   \n",
       "1           -0.418166        -0.348384        0.069783               22   \n",
       "2            0.042849        -0.096173        0.139023                8   \n",
       "3            0.234161        -0.011916        0.246077                2   \n",
       "4            0.190783        -0.101702        0.292484               10   \n",
       "5           -0.507174        -0.404815        0.102359               28   \n",
       "6           -0.405618        -0.346601        0.059017               19   \n",
       "7            0.104754        -0.078321        0.183075                5   \n",
       "8            0.271360         0.002565        0.268796                1   \n",
       "9            0.154313        -0.163637        0.317951               14   \n",
       "10          -0.491914        -0.399196        0.092718               25   \n",
       "11          -0.378218        -0.338962        0.039255               17   \n",
       "12           0.121723        -0.092353        0.214076                6   \n",
       "13           0.258311        -0.043792        0.302103                3   \n",
       "14           0.089949        -0.231599        0.321549               15   \n",
       "15          -0.501372        -0.408399        0.092974               32   \n",
       "16          -0.396682        -0.357146        0.039536               24   \n",
       "17           0.081159        -0.133468        0.214627               13   \n",
       "18           0.201229        -0.105606        0.306835               11   \n",
       "19           0.007428        -0.318732        0.326160               16   \n",
       "20          -0.609697        -0.462142        0.147554               40   \n",
       "21          -0.598789        -0.455698        0.143091               35   \n",
       "22          -0.515957        -0.406391        0.109565               30   \n",
       "23          -0.418163        -0.348310        0.069853               21   \n",
       "24           0.042623        -0.096251        0.138873                9   \n",
       "25          -0.608962        -0.462113        0.146850               38   \n",
       "26          -0.597295        -0.455624        0.141671               34   \n",
       "27          -0.507250        -0.404785        0.102464               27   \n",
       "28          -0.405720        -0.346714        0.059006               20   \n",
       "29           0.104676        -0.078287        0.182963                4   \n",
       "30          -0.607105        -0.461316        0.145789               37   \n",
       "31          -0.593649        -0.454046        0.139603               33   \n",
       "32          -0.491969        -0.399318        0.092651               26   \n",
       "33          -0.378336        -0.339053        0.039282               18   \n",
       "34           0.121537        -0.092359        0.213896                7   \n",
       "35          -0.608092        -0.462141        0.145951               39   \n",
       "36          -0.595614        -0.455709        0.139905               36   \n",
       "37          -0.501415        -0.408352        0.093063               31   \n",
       "38          -0.396766        -0.357141        0.039625               23   \n",
       "39           0.081039        -0.133382        0.214421               12   \n",
       "\n",
       "    split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "0             0.032566            0.050419          0.041492         0.008927  \n",
       "1             0.062480            0.097600          0.080040         0.017560  \n",
       "2             0.234001            0.357165          0.295583         0.061582  \n",
       "3             0.352395            0.509369          0.430882         0.078487  \n",
       "4             0.568327            0.707113          0.637720         0.069393  \n",
       "5             0.038248            0.057765          0.048007         0.009759  \n",
       "6             0.072922            0.110163          0.091542         0.018620  \n",
       "7             0.281466            0.398309          0.339888         0.058421  \n",
       "8             0.419000            0.564233          0.491616         0.072617  \n",
       "9             0.659658            0.776814          0.718236         0.058578  \n",
       "10            0.047881            0.062616          0.055249         0.007368  \n",
       "11            0.091342            0.119509          0.105426         0.014083  \n",
       "12            0.331880            0.426112          0.378996         0.047116  \n",
       "13            0.486912            0.615817          0.551365         0.064453  \n",
       "14            0.742957            0.842246          0.792601         0.049644  \n",
       "15            0.056848            0.068749          0.062798         0.005950  \n",
       "16            0.108329            0.130952          0.119640         0.011311  \n",
       "17            0.393372            0.464091          0.428731         0.035359  \n",
       "18            0.567123            0.657125          0.612124         0.045001  \n",
       "19            0.836340            0.898052          0.867196         0.030856  \n",
       "20            0.003401            0.005270          0.004335         0.000934  \n",
       "21            0.006769            0.010487          0.008628         0.001859  \n",
       "22            0.032552            0.050397          0.041475         0.008923  \n",
       "23            0.062455            0.097576          0.080015         0.017560  \n",
       "24            0.233963            0.357059          0.295511         0.061548  \n",
       "25            0.003996            0.006035          0.005016         0.001020  \n",
       "26            0.007953            0.012011          0.009982         0.002029  \n",
       "27            0.038232            0.057741          0.047986         0.009754  \n",
       "28            0.072893            0.110118          0.091506         0.018613  \n",
       "29            0.281419            0.398230          0.339824         0.058406  \n",
       "30            0.005001            0.006544          0.005773         0.000772  \n",
       "31            0.009953            0.013024          0.011488         0.001535  \n",
       "32            0.047860            0.062589          0.055225         0.007365  \n",
       "33            0.091302            0.119450          0.105376         0.014074  \n",
       "34            0.331793            0.426001          0.378897         0.047104  \n",
       "35            0.005941            0.007185          0.006563         0.000622  \n",
       "36            0.011823            0.014299          0.013061         0.001238  \n",
       "37            0.056824            0.068719          0.062771         0.005948  \n",
       "38            0.108285            0.130898          0.119592         0.011307  \n",
       "39            0.393246            0.463977          0.428611         0.035365  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gbc_grid_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
